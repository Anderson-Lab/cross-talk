{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdkGRLgcFN1o"
   },
   "source": [
    "Example pipeline for text to KG (v1)\n",
    "\n",
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Defined Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_DIR=\"/mnt/clbp/paul/cross-talk/texts.examples/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wdK8WtAF8ES"
   },
   "source": [
    "## License Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "61uNqFkvF-UU"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "with open(\"/mnt/clbp/jsl_lic.json\") as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "# Defining license key-value pairs as local variables\n",
    "locals().update(license_keys)\n",
    "\n",
    "# Adding license key-value pairs to environment variables\n",
    "os.environ.update(license_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "1PE2aPkzz_Xg"
   },
   "outputs": [],
   "source": [
    "# Installing pyspark and spark-nlp\n",
    "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n",
    "\n",
    "# Installing Spark NLP Healthcare\n",
    "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET\n",
    "\n",
    "# Installing Spark NLP Display Library for visualization\n",
    "! pip install -q spark-nlp-display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "RpdYuemp0qwP",
    "outputId": "890f71a7-cca1-4806-f22f-8722ec15df0a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n",
      "Spark NLP Version : 5.0.2\n",
      "Spark NLP_JSL Version : 5.0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://paul:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP Licensed</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8f35f1ed10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "\n",
    "import sparknlp\n",
    "import sparknlp_jsl\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "params = {\"spark.driver.memory\":\"26G\",\n",
    "          \"spark.kryoserializer.buffer.max\":\"2000M\",\n",
    "          \"spark.driver.maxResultSize\":\"2000M\"}\n",
    "\n",
    "spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n",
    "\n",
    "print(\"Spark NLP Version :\", sparknlp.version())\n",
    "print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coresolution of Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spanbert_base_coref download started this may take some time.\n",
      "Approximate size to download 540.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Import the required modules and classes\n",
    "from sparknlp.base import DocumentAssembler, Pipeline\n",
    "from sparknlp.annotator import (\n",
    "    SentenceDetector,\n",
    "    Tokenizer,\n",
    "    SpanBertCorefModel\n",
    ")\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Step 1: Transforms raw texts to `document` annotation\n",
    "document = DocumentAssembler() \\\n",
    "            .setInputCol(\"text\") \\\n",
    "            .setOutputCol(\"document\")\n",
    "\n",
    "# Step 2: Sentence Detection\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "            .setInputCols(\"document\") \\\n",
    "            .setOutputCol(\"sentences\")\n",
    "\n",
    "# Step 3: Tokenization\n",
    "token = Tokenizer() \\\n",
    "            .setInputCols(\"sentences\") \\\n",
    "            .setOutputCol(\"tokens\") \\\n",
    "            .setContextChars([\"(\", \")\", \"?\", \"!\", \".\", \",\"])\n",
    "\n",
    "# Step 4: Coreference Resolution\n",
    "corefResolution= SpanBertCorefModel().pretrained(\"spanbert_base_coref\")\\\n",
    "            .setInputCols([\"sentences\", \"tokens\"]) \\\n",
    "            .setOutputCol(\"corefs\") \\\n",
    "            .setCaseSensitive(False)\n",
    "            \n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(stages=[document, sentenceDetector, token, corefResolution])\n",
    "\n",
    "# Create the dataframe\n",
    "data = spark.createDataFrame([[\"Ana is a Graduate Student at UT Dallas. She loves working in Natural Language Processing at the Institute. Her hobbies include blogging, dancing and singing.\"]]).toDF(\"text\")\n",
    "\n",
    "# Fit the dataframe to the pipeline to get the model\n",
    "model = pipeline.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve(text,results):\n",
    "    pieces = []\n",
    "    current = 0\n",
    "    for ix in results.index:\n",
    "        print(results)\n",
    "        row = results.loc[ix,\"coref\"]\n",
    "        begin,end = row['begin'],row['end']\n",
    "        metadata = row['metadata']\n",
    "        head = metadata['head']\n",
    "        if head != \"ROOT\":\n",
    "            text2_up_to = text[current:begin]\n",
    "            pieces.append(text2_up_to)\n",
    "            pieces.append(head)\n",
    "            current = (end+1)\n",
    "    pieces.append(text[current:])\n",
    "    return \"\".join(pieces)\n",
    "\n",
    "def resolveText2Text(text):\n",
    "    data_2 = spark.createDataFrame([[text]]).toDF(\"text\")\n",
    "    model = pipeline.fit(data_2)\n",
    "\n",
    "    try:\n",
    "        results = model.transform(data_2).selectExpr(\"explode(corefs) AS coref\").toPandas()\n",
    "        text2 = resolve(text,results)\n",
    "    except:\n",
    "        print(\"Failed on the following paragraph:\")\n",
    "        print(text)        \n",
    "        text2 = text\n",
    "    return text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/mnt/clbp/paul/cross-talk/texts.examples//coref_resolved/’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir $SRC_DIR/coref_resolved/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/clbp/paul/cross-talk/texts.examples/physical_activity.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical activity imposes fluctuating loads and movements onto the spine\n",
      "Physical activity imposes fluctuating loads and movements onto the spine\n",
      "\n",
      "Literature has demonstrated a dose-dependent influence of loading, where both sedentary and strenuous activities are thought to be detrimental\n",
      "Literature has demonstrated a dose-dependent influence of loading, where both sedentary and strenuous activities are thought to be detrimental\n",
      "\n",
      "Physical activity categories may include occupational, recreational, and sports related\n",
      "Physical activity categories may include occupational, recreational, and sports related\n",
      "\n",
      "The World Health Organization defines physical activity as any bodily movement produced by skeletal muscle that results in a substantial increase over the resting energy expenditure\n",
      "The World Health Organization defines physical activity as any bodily movement produced by skeletal muscle that results in a substantial increase over the resting energy expenditure\n",
      "\n",
      "Where disability focuses on what people cannot do, the concept of physical activity focuses on what people are able to do or actually do in daily living\n",
      "Where disability focuses on what people cannot do, the concept of physical activity focuses on what people are able to do or actually do in daily living\n",
      "\n",
      "Three studies reported data for physical functioning (two RPF with little SOE confidence) and activity (two RPF with little to some SOE confidence) as assessed by questionnaire or accelerometry in relation to work status, disability, and pain severity\n",
      "Three studies reported data for physical functioning (two RPF with little SOE confidence) and activity (two RPF with little to some SOE confidence) as assessed by questionnaire or accelerometry in relation to work status, disability, and pain severity\n",
      "\n",
      "Potential mechanisms discussed include the fear-avoidance or avoidance-endurance models, hypothesizing that patients avoid activities due to fear of reinjury that, in turn, leads to deconditioning and further disability\n",
      "Potential mechanisms discussed include the fear-avoidance or avoidance-endurance models, hypothesizing that patients avoid activities due to fear of reinjury that, in turn, leads to deconditioning and further disability\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/mnt/clbp/paul/cross-talk/texts.examples/spinal_cord.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               coref\n",
      "0  (dependency, 187, 194, the para, {'head': 'ROO...\n",
      "1  (dependency, 248, 263, these subsystems, {'hea...\n",
      "2  (dependency, 481, 658, proprioception , which ...\n",
      "3  (dependency, 306, 309, they, {'head': 'proprio...\n",
      "                                               coref\n",
      "0  (dependency, 187, 194, the para, {'head': 'ROO...\n",
      "1  (dependency, 248, 263, these subsystems, {'hea...\n",
      "2  (dependency, 481, 658, proprioception , which ...\n",
      "3  (dependency, 306, 309, they, {'head': 'proprio...\n",
      "                                               coref\n",
      "0  (dependency, 187, 194, the para, {'head': 'ROO...\n",
      "1  (dependency, 248, 263, these subsystems, {'hea...\n",
      "2  (dependency, 481, 658, proprioception , which ...\n",
      "3  (dependency, 306, 309, they, {'head': 'proprio...\n",
      "                                               coref\n",
      "0  (dependency, 187, 194, the para, {'head': 'ROO...\n",
      "1  (dependency, 248, 263, these subsystems, {'hea...\n",
      "2  (dependency, 481, 658, proprioception , which ...\n",
      "3  (dependency, 306, 309, they, {'head': 'proprio...\n",
      "The spinal column is biomechanically stabilized by three subsystems: 1) passive subsystem that includes bone, cartilage, ligaments, intervertebral disc; 2) active subsystem that includes the paraspinal muscles; and 3) the neural control subsystem\n",
      "The spinal column is biomechanically stabilized by three subsystems: 1) passive subsystem that includes bone, cartilage, ligaments, intervertebral disc; 2) active subsystem that includes the paraspinal muscles; and 3) the neural control subsystem\n",
      "\n",
      "These subsystems are often conceptualized separately, but they are functionally interdependent\n",
      "the para are often conceptualized separately, but proprioception , which refers to afferent information arising from internal peripheral areas that contribute to postural control , joint stability , and several conscious sensations are functionally interdependent\n",
      "\n",
      "Motor control and function include muscle recruitment, strength, and endurance\n",
      "Motor control and function include muscle recruitment, strength, and endurance\n",
      "\n",
      "An important feedback component of neuromotor control is proprioception, which refers to afferent information arising from internal peripheral areas that contribute to postural control, joint stability, and several conscious sensations\n",
      "An important feedback component of neuromotor control is proprioception, which refers to afferent information arising from internal peripheral areas that contribute to postural control, joint stability, and several conscious sensations\n",
      "\n",
      "Movement and control disorders presumably lead to a proprioceptive deficit, because of stress on local muscle spindles and joint receptors in the painful area resulting from stress to a joint caused by an individual’s maladaptive movement\n",
      "Movement and control disorders presumably lead to a proprioceptive deficit, because of stress on local muscle spindles and joint receptors in the painful area resulting from stress to a joint caused by an individual’s maladaptive movement\n",
      "\n",
      "Subsequently, abnormal joint and tissue loading during daily activities and postures may affect local proprioceptors and maintain this vicious cycle\n",
      "Subsequently, abnormal joint and tissue loading during daily activities and postures may affect local proprioceptors and maintain this vicious cycle\n",
      "\n",
      "Changes in muscle activity have been linked to spinal pain (muscle-tension or pain-spasm-pain model) or restriction of spinal motion (pain adaptation)\n",
      "Changes in muscle activity have been linked to spinal pain (muscle-tension or pain-spasm-pain model) or restriction of spinal motion (pain adaptation)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/mnt/clbp/paul/cross-talk/texts.examples/personal_medical_history.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 411:======================================================>(95 + 1) / 96]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               coref\n",
      "0  (dependency, 0, 32, the personal history of a ...\n",
      "1  (dependency, 134, 135, it, {'head': 'the perso...\n",
      "                                               coref\n",
      "0  (dependency, 0, 32, the personal history of a ...\n",
      "1  (dependency, 134, 135, it, {'head': 'the perso...\n",
      "The personal history of a patient spans many facets of life including employment status and occupation, marital and insurance status\n",
      "The personal history of a patient spans many facets of life including employment status and occupation, marital and insurance status\n",
      "\n",
      "It also includes social history such as alcohol, tobacco and substance use in addition to personal preferences, expectations, habits such as sleep schedule, clothing choices, and diet\n",
      "the personal history of a patient also includes social history such as alcohol, tobacco and substance use in addition to personal preferences, expectations, habits such as sleep schedule, clothing choices, and diet\n",
      "\n",
      "The patient's medical history of isolated and chronic illnesses is important as well\n",
      "The patient's medical history of isolated and chronic illnesses is important as well\n",
      "\n",
      "All of these entities likely contribute to how pain is experienced in each individual\n",
      "All of these entities likely contribute to how pain is experienced in each individual\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "path = SRC_DIR\n",
    "files = glob.glob(path + '/*.json')\n",
    "for file in files:\n",
    "    print(file)\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "    paragraphs = data['text'].split(\"\\n\\n\")\n",
    "    new_paragraphs = []\n",
    "    for text in paragraphs:        \n",
    "        new_paragraphs.append(resolveText2Text(text))\n",
    "    new_file = path+\"/coref_resolved/\"+file.split(\"/\")[-1]\n",
    "    with open(new_file,\"w\") as f:\n",
    "        data['text'] = \"\\n\\n\".join(new_paragraphs)\n",
    "        f.write(json.dumps(data))\n",
    "\n",
    "    orig_contents = json.loads(open(file).read())\n",
    "    orig_sentences = orig_contents[\"text\"].split(\".\")\n",
    "    new_contents = json.loads(open(new_file).read())\n",
    "    new_sentences = new_contents[\"text\"].split(\".\")\n",
    "    for i in range(len(orig_sentences)):\n",
    "        print(orig_sentences[i].strip())\n",
    "        print(new_sentences[i].strip())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = open(\"/mnt/clbp/.openai_api_key.txt\").read().strip()\n",
    "\n",
    "max_tokens = 4097\n",
    "min_num_words_in_sentences = 4\n",
    "min_num_words_in_paragraph = min_num_words_in_sentences\n",
    "min_len_sentence = min_num_words_in_sentences*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/mnt/clbp/paul/cross-talk/texts.examples//coref_resolved/triplets/’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir $SRC_DIR/coref_resolved/triplets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import io\n",
    "import glob\n",
    "\n",
    "min_num_words_in_paragraph = 3\n",
    "\n",
    "def get_triplets(contents,field):\n",
    "    all_sentences_with_results = []\n",
    "    all_sentences_without_results = []\n",
    "    \n",
    "    output = []\n",
    "    paragraphs = contents[field].split(\"\\n\\n\")\n",
    "    for paragraph in paragraphs:\n",
    "        output.append({\"paragraph\": {\"text\":paragraph}})\n",
    "        num_words = len(paragraph.split(\" \"))\n",
    "        if num_words < min_num_words_in_paragraph:\n",
    "            continue\n",
    "\n",
    "        sentences_with_results = []\n",
    "        sentences_without_results = []\n",
    "        for sent in paragraph.split(\".\"):\n",
    "            if sent.strip() == \"\":\n",
    "                continue\n",
    "            messages=[\n",
    "                  {\"role\": \"system\", \"content\": \"Rewrite a sentence such that each sentence has one subject and one object. Keep the meaning the same and write in active voice. Your answer should be a numbered list.\"},\n",
    "                  {\"role\": \"user\", \"content\": sent }\n",
    "            ]\n",
    "            response = openai.ChatCompletion.create(\n",
    "              model=\"gpt-3.5-turbo\",\n",
    "              messages=messages,\n",
    "              temperature=0,\n",
    "              max_tokens=1024,\n",
    "              top_p=1,\n",
    "              frequency_penalty=0,\n",
    "              presence_penalty=0\n",
    "            )\n",
    "            sentences = response['choices'][0]['message']['content'].split(\"\\n\")\n",
    "            if sentences[0].strip() == \"None\":\n",
    "                continue\n",
    "            sentences_with_results += [\" \".join(s.split(\" \")[1:]) for s in sentences] # Remove the number\n",
    "            \n",
    "        output[-1][\"paragraph\"][\"sentences_with_results\"] = [{\"text\":s, \"clauses\": []} for s in sentences_with_results]\n",
    "        output[-1][\"paragraph\"][\"sentences_without_results\"] = [{\"text\":s, \"clauses\": []} for s in sentences_without_results]\n",
    "\n",
    "        print(\"Sentences with results:\")\n",
    "        print(\"\\n\".join(sentences_with_results))\n",
    "        for j,sentence in enumerate(sentences_with_results):\n",
    "            print(\"Sentence\",j+1,\"out of\",len(sentences_with_results))\n",
    "\n",
    "\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Break down this sentence into more straightforward sentences. Your answer should be a numbered list.\"},\n",
    "                    {\"role\": \"user\", \"content\": sentence }\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_tokens=1024,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0\n",
    "            )\n",
    "            time.sleep(1)\n",
    "            clauses = [\" \".join(clause.split(\" \")[1:]) for clause in response['choices'][0]['message']['content'].split(\"\\n\")]\n",
    "            paragraph_clauses = \" \".join(clauses)\n",
    "            clauses = []\n",
    "            for c in resolveText2Text(paragraph_clauses).strip().split(\".\"):\n",
    "                c = c.strip()\n",
    "                if c == \"\":\n",
    "                    continue\n",
    "                clauses.append(f\"{c}.\")\n",
    "            output[-1][\"paragraph\"][\"sentences_with_results\"][j][\"clauses\"] = [{\"text\": c} for c in clauses]\n",
    "            for i, clause in enumerate(clauses):  \n",
    "                print(\"Clause\",i+1,\"out of\",len(clauses))\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You will be provided a sentence, and your task is split it into a subject, verb, and object. Return your answer as JSON with keys subject, verb, object.\"},\n",
    "                        {\"role\": \"user\", \"content\": clause }\n",
    "                    ],\n",
    "                    temperature=0,\n",
    "                    max_tokens=1024,\n",
    "                    top_p=1,\n",
    "                    frequency_penalty=0,\n",
    "                    presence_penalty=0\n",
    "                )\n",
    "                time.sleep(1)\n",
    "                content = response['choices'][0]['message']['content']\n",
    "                output[-1][\"paragraph\"][\"sentences_with_results\"][j][\"clauses\"][i][\"triplet\"] = json.loads(content)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences with results:\n",
      "The patient's personal history includes personal preferences.\n",
      "The patient's personal history includes expectations.\n",
      "The patient's personal history includes habits, such as sleep schedule.\n",
      "The patient's personal history includes habits, such as clothing choices.\n",
      "The patient's personal history includes habits, such as diet.\n",
      "Games are included in a patient's personal history.\n",
      "Sports are included in a patient's personal history.\n",
      "Relationships are included in a patient's personal history.\n",
      "Sentence 1 out of 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 2\n",
      "Clause 2 out of 2\n",
      "Sentence 2 out of 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 2\n",
      "Clause 2 out of 2\n",
      "Sentence 3 out of 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 3\n",
      "Clause 2 out of 3\n",
      "Clause 3 out of 3\n",
      "Sentence 4 out of 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 3\n",
      "Clause 2 out of 3\n",
      "Clause 3 out of 3\n",
      "Sentence 5 out of 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 3\n",
      "Clause 2 out of 3\n",
      "Clause 3 out of 3\n",
      "Sentence 6 out of 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 3\n",
      "Clause 2 out of 3\n",
      "Clause 3 out of 3\n",
      "Sentence 7 out of 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 2\n",
      "Clause 2 out of 2\n",
      "Sentence 8 out of 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 4\n",
      "Clause 2 out of 4\n",
      "Clause 3 out of 4\n",
      "Clause 4 out of 4\n"
     ]
    }
   ],
   "source": [
    "contents = {\"text\": \"A patient's personal history also includes personal preferences, expectations, habits, such as sleep schedule, clothing choices, and diet. A patient's personal history also includes games, sports, and relationships.\"}\n",
    "outputs = get_triplets(contents,\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'paragraph': {'text': \"A patient's personal history also includes personal preferences, expectations, habits, such as sleep schedule, clothing choices, and diet. A patient's personal history also includes games, sports, and relationships.\",\n",
       "   'sentences_with_results': [{'text': \"The patient's personal history includes personal preferences.\",\n",
       "     'clauses': [{'text': 'The patient has a personal history.',\n",
       "       'triplet': {'subject': 'patient',\n",
       "        'verb': 'has',\n",
       "        'object': 'a personal history'}},\n",
       "      {'text': 'a personal history includes personal preferences.',\n",
       "       'triplet': {'subject': 'a personal history',\n",
       "        'verb': 'includes',\n",
       "        'object': 'personal preferences'}}]},\n",
       "    {'text': \"The patient's personal history includes expectations.\",\n",
       "     'clauses': [{'text': 'The patient has a personal history.',\n",
       "       'triplet': {'subject': 'patient',\n",
       "        'verb': 'has',\n",
       "        'object': 'a personal history'}},\n",
       "      {'text': 'a personal history includes expectations.',\n",
       "       'triplet': {'subject': 'a personal history',\n",
       "        'verb': 'includes',\n",
       "        'object': 'expectations'}}]},\n",
       "    {'text': \"The patient's personal history includes habits, such as sleep schedule.\",\n",
       "     'clauses': [{'text': 'The patient has a personal history.',\n",
       "       'triplet': {'subject': 'patient',\n",
       "        'verb': 'has',\n",
       "        'object': 'a personal history'}},\n",
       "      {'text': 'a personal history includes habits.',\n",
       "       'triplet': {'subject': 'a personal history',\n",
       "        'verb': 'includes',\n",
       "        'object': 'habits'}},\n",
       "      {'text': 'One of the habits included in a personal history is the sleep schedule.',\n",
       "       'triplet': {'subject': 'One of the habits',\n",
       "        'verb': 'is included',\n",
       "        'object': 'the sleep schedule'}}]},\n",
       "    {'text': \"The patient's personal history includes habits, such as clothing choices.\",\n",
       "     'clauses': [{'text': 'The patient has a personal history.',\n",
       "       'triplet': {'subject': 'patient',\n",
       "        'verb': 'has',\n",
       "        'object': 'a personal history'}},\n",
       "      {'text': 'a personal history includes habits.',\n",
       "       'triplet': {'subject': 'a personal history',\n",
       "        'verb': 'includes',\n",
       "        'object': 'habits'}},\n",
       "      {'text': 'One of the habits included in a personal history is clothing choices.',\n",
       "       'triplet': {'subject': 'One of the habits',\n",
       "        'verb': 'is',\n",
       "        'object': 'clothing choices'}}]},\n",
       "    {'text': \"The patient's personal history includes habits, such as diet.\",\n",
       "     'clauses': [{'text': 'The patient has a personal history.',\n",
       "       'triplet': {'subject': 'patient',\n",
       "        'verb': 'has',\n",
       "        'object': 'a personal history'}},\n",
       "      {'text': 'a personal history includes habits.',\n",
       "       'triplet': {'subject': 'a personal history',\n",
       "        'verb': 'includes',\n",
       "        'object': 'habits'}},\n",
       "      {'text': 'One of the habits included in a personal history is the patient diet.',\n",
       "       'triplet': {'subject': 'One of the habits',\n",
       "        'verb': 'is included',\n",
       "        'object': 'the patient diet'}}]},\n",
       "    {'text': \"Games are included in a patient's personal history.\",\n",
       "     'clauses': [{'text': \"Games are part of a patient's personal history.\",\n",
       "       'triplet': {'subject': 'Games',\n",
       "        'verb': 'are',\n",
       "        'object': \"part of a patient's personal history\"}},\n",
       "      {'text': 'Games are included or mentioned in a patient personal history.',\n",
       "       'triplet': {'subject': 'Games',\n",
       "        'verb': 'are included or mentioned in',\n",
       "        'object': 'a patient personal history'}},\n",
       "      {'text': 'a patient personal history includes games.',\n",
       "       'triplet': {'subject': 'patient personal history',\n",
       "        'verb': 'includes',\n",
       "        'object': 'games'}}]},\n",
       "    {'text': \"Sports are included in a patient's personal history.\",\n",
       "     'clauses': [{'text': \"A patient's personal history includes sports.\",\n",
       "       'triplet': {'subject': \"patient's personal history\",\n",
       "        'verb': 'includes',\n",
       "        'object': 'sports'}},\n",
       "      {'text': \"Sports are part of a patient's personal history.\",\n",
       "       'triplet': {'subject': 'Sports',\n",
       "        'verb': 'are',\n",
       "        'object': \"part of a patient's personal history\"}}]},\n",
       "    {'text': \"Relationships are included in a patient's personal history.\",\n",
       "     'clauses': [{'text': \"Relationships are a part of a patient's personal history.\",\n",
       "       'triplet': {'subject': 'Relationships',\n",
       "        'verb': 'are',\n",
       "        'object': \"a part of a patient's personal history\"}},\n",
       "      {'text': \"Relationships are included when documenting a patient's personal history.\",\n",
       "       'triplet': {'subject': 'Relationships',\n",
       "        'verb': 'are included',\n",
       "        'object': \"when documenting a patient's personal history\"}},\n",
       "      {'text': \"When discussing a patient's personal history, relationships are taken into account.\",\n",
       "       'triplet': {'subject': 'relationships',\n",
       "        'verb': 'are taken into account',\n",
       "        'object': \"when discussing a patient's personal history\"}},\n",
       "      {'text': 'The personal history of a patient includes information about a patient relationships.',\n",
       "       'triplet': {'subject': 'The personal history of a patient',\n",
       "        'verb': 'includes',\n",
       "        'object': \"information about a patient's relationships\"}}]}],\n",
       "   'sentences_without_results': []}}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/clbp/paul/cross-talk/texts.examples//coref_resolved/spinal_cord.json\n",
      "Sentences with results:\n",
      "Three subsystems biomechanically stabilize the spinal column: the passive subsystem includes bone, cartilage, ligaments, and intervertebral disc.\n",
      "The paraspinal muscles form the active subsystem that biomechanically stabilizes the spinal column.\n",
      "The neural control subsystem also plays a role in biomechanically stabilizing the spinal column.\n",
      "People often conceptualize the para separately, but proprioception functionally interdepends on afferent information arising from internal peripheral areas.\n",
      "Proprioception contributes to postural control, joint stability, and several conscious sensations.\n",
      "Afferent information from internal peripheral areas contributes to postural control, joint stability, and several conscious sensations.\n",
      "Postural control, joint stability, and several conscious sensations rely on afferent information from internal peripheral areas.\n",
      "The para and proprioception are often conceptualized separately, but they functionally interdepend on afferent information from internal peripheral areas.\n",
      "Muscle recruitment is included in motor control and function.\n",
      "Strength is included in motor control and function.\n",
      "Endurance is included in motor control and function.\n",
      "Proprioception is an important feedback component of neuromotor control.\n",
      "Proprioception refers to afferent information arising from internal peripheral areas.\n",
      "Proprioception contributes to postural control, joint stability, and several conscious sensations.\n",
      "Presumably, movement and control disorders lead to a proprioceptive deficit.\n",
      "Stress on local muscle spindles and joint receptors in the painful area results from stress to a joint caused by an individual's maladaptive movement.\n",
      "Abnormal joint and tissue loading during daily activities and postures may affect local proprioceptors.\n",
      "This may maintain the vicious cycle.\n",
      "Researchers have linked changes in muscle activity to spinal pain, specifically the muscle-tension or pain-spasm-pain model.\n",
      "The pain adaptation theory suggests that changes in muscle activity can be linked to the restriction of spinal motion and subsequent spinal pain.\n",
      "Sentence 1 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 3\n",
      "Clause 2 out of 3\n",
      "Clause 3 out of 3\n",
      "Sentence 2 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 5\n",
      "Clause 2 out of 5\n",
      "Clause 3 out of 5\n",
      "Clause 4 out of 5\n",
      "Clause 5 out of 5\n",
      "Sentence 3 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 2\n",
      "Clause 2 out of 2\n",
      "Sentence 4 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 4\n",
      "Clause 2 out of 4\n",
      "Clause 3 out of 4\n",
      "Clause 4 out of 4\n",
      "Sentence 5 out of 20\n",
      "Clause 1 out of 3\n",
      "Clause 2 out of 3\n",
      "Clause 3 out of 3\n",
      "Sentence 6 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 4\n",
      "Clause 2 out of 4\n",
      "Clause 3 out of 4\n",
      "Clause 4 out of 4\n",
      "Sentence 7 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 2\n",
      "Clause 2 out of 2\n",
      "Sentence 8 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 3\n",
      "Clause 2 out of 3\n",
      "Clause 3 out of 3\n",
      "Sentence 9 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 2\n",
      "Clause 2 out of 2\n",
      "Sentence 10 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 2\n",
      "Clause 2 out of 2\n",
      "Sentence 11 out of 20\n",
      "Clause 1 out of 2\n",
      "Clause 2 out of 2\n",
      "Sentence 12 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 2\n",
      "Clause 2 out of 2\n",
      "Sentence 13 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 3\n",
      "Clause 2 out of 3\n",
      "Clause 3 out of 3\n",
      "Sentence 14 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 3\n",
      "Clause 2 out of 3\n",
      "Clause 3 out of 3\n",
      "Sentence 15 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 8\n",
      "Clause 2 out of 8\n",
      "Clause 3 out of 8\n",
      "Clause 4 out of 8\n",
      "Clause 5 out of 8\n",
      "Clause 6 out of 8\n",
      "Clause 7 out of 8\n",
      "Clause 8 out of 8\n",
      "Sentence 16 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 4\n",
      "Clause 2 out of 4\n",
      "Clause 3 out of 4\n",
      "Clause 4 out of 4\n",
      "Sentence 17 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 2\n",
      "Clause 2 out of 2\n",
      "Sentence 18 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 2\n",
      "Clause 2 out of 2\n",
      "Sentence 19 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 3\n",
      "Clause 2 out of 3\n",
      "Clause 3 out of 3\n",
      "Sentence 20 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 3\n",
      "Clause 2 out of 3\n",
      "Clause 3 out of 3\n",
      "/mnt/clbp/paul/cross-talk/texts.examples//coref_resolved/personal_medical_history.json\n",
      "Sentences with results:\n",
      "A patient's personal history includes their employment status.\n",
      "A patient's personal history includes their occupation.\n",
      "A patient's personal history includes their marital status.\n",
      "A patient's personal history includes their insurance status.\n",
      "A patient's personal history includes social history, which encompasses alcohol, tobacco, and substance use.\n",
      "A patient's personal history also includes personal preferences, expectations, and habits such as sleep schedule, clothing choices, and diet.\n",
      "The medical history of the patient's isolated and chronic illnesses is important.\n",
      "The isolated and chronic illnesses of the patient have an important medical history.\n",
      "Each individual likely experiences pain based on the contributions of all these entities.\n",
      "All these entities likely contribute to the individual's experience of pain.\n",
      "The experience of pain in each individual is likely influenced by all these entities.\n",
      "All these entities likely play a role in how pain is experienced by each individual.\n",
      "Each individual's experience of pain is likely shaped by the contributions of all these entities.\n",
      "Sentence 1 out of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 4\n",
      "Clause 2 out of 4\n",
      "Clause 3 out of 4\n",
      "Clause 4 out of 4\n",
      "Sentence 2 out of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 5\n",
      "Clause 2 out of 5\n",
      "Clause 3 out of 5\n",
      "Clause 4 out of 5\n",
      "Clause 5 out of 5\n",
      "Sentence 3 out of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 2\n",
      "Clause 2 out of 2\n",
      "Sentence 4 out of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 2\n",
      "Clause 2 out of 2\n",
      "Sentence 5 out of 13\n",
      "Clause 1 out of 4\n",
      "Clause 2 out of 4\n",
      "Clause 3 out of 4\n",
      "Clause 4 out of 4\n",
      "Sentence 6 out of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 2\n",
      "Clause 2 out of 2\n",
      "Sentence 7 out of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 2\n",
      "Clause 2 out of 2\n",
      "Sentence 8 out of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 3\n",
      "Clause 2 out of 3\n",
      "Clause 3 out of 3\n",
      "Sentence 9 out of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 2\n",
      "Clause 2 out of 2\n",
      "Sentence 10 out of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 3\n",
      "Clause 2 out of 3\n",
      "Clause 3 out of 3\n",
      "Sentence 11 out of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 3\n",
      "Clause 2 out of 3\n",
      "Clause 3 out of 3\n",
      "Sentence 12 out of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 3\n",
      "Clause 2 out of 3\n",
      "Clause 3 out of 3\n",
      "Sentence 13 out of 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1 out of 4\n",
      "Clause 2 out of 4\n",
      "Clause 3 out of 4\n",
      "Clause 4 out of 4\n"
     ]
    }
   ],
   "source": [
    "path = SRC_DIR\n",
    "files = glob.glob(path + '/coref_resolved/*.json')\n",
    "for file in files[1:]:\n",
    "    print(file)\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "    output = get_triplets(data,\"text\")\n",
    "    outfile = path + '/coref_resolved/triplets/'+file.split(\"/\")[-1]\n",
    "    open(outfile,\"w\").write(json.dumps(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplets to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/clbp/paul/cross-talk/texts.examples/coref_resolved/triplets/physical_activity.json\n",
      "physical activity|imposes|loads and movements onto the spine\n",
      "loads and movements|are|not constant, but instead fluctuate\n",
      "fluctuating loads and movements|can have|an impact on the spine\n",
      "physical activity|involves|putting stress and strain on the spine\n",
      "stress and strain|cause|the spine to move in different ways\n",
      "movements of the spine|are|not constant, but rather change or vary\n",
      "the spine|is|a part of the body that is subjected to various loads and movements\n",
      "various loads and movements|are caused by|physical activity\n",
      "the spine|experiences|various loads and movements\n",
      "loading in literature|has shown|that it has an impact that depends on the dose\n",
      "sedentary and strenuous activities|are believed to have|negative effects\n",
      "literature|has shown|that loading has a dose-dependent influence\n",
      "sedentary activities|are thought|to be detrimental\n",
      "strenuous activities|are|also thought to be detrimental\n",
      "the influence of loading in literature|is|dose-dependent\n",
      "sedentary activities|are thought|to be detrimental\n",
      "strenuous activities|are|also thought to be detrimental\n",
      "literature|suggests|that loading has a dose-dependent influence\n",
      "sedentary activities|are thought|to be detrimental\n",
      "strenuous activities|are|also thought to be detrimental\n",
      "occupational activities|refer to|the tasks and responsibilities that people perform in people jobs\n",
      "tasks and responsibilities|perform|various categories of physical activity\n",
      "physical activity categories|can include|tasks that require physical exertion or movement\n",
      "examples of physical activity categories in occupational activities|may include|lifting heavy objects, walking or standing for long periods, or operating machinery\n",
      "recreational activities|are|activities that people do for fun and enjoyment\n",
      "recreational activities|can include|different categories of physical activity\n",
      "sports-related activities|refer to|activities that are related to sports\n",
      "activities|may include|different categories of physical activity\n",
      "the world health organization|is|an international organization\n",
      "the world health organization|has|a definition for physical activity\n",
      "physical activity|refers to|any bodily movement\n",
      "any bodily movement|is produced by|skeletal muscle\n",
      "skeletal muscle|is responsible for|producing bodily movement\n",
      "bodily movement|is|a result of the actions of skeletal muscle\n",
      "bodily movement|refers to|any physical activity or exercise that involves the movement of the body\n",
      "resting energy expenditure|is|the amount of energy or calories that the body burns while at rest\n",
      "there|is|a significant increase in the amount of energy that the body burns compared to when the body is at rest\n",
      "the concept of physical activity|is|about what people are able to do or actually do in people daily lives\n",
      "the concept of physical activity|emphasizes|the actions and abilities of individuals in terms of physical movement\n",
      "the concept of physical activity|encompasses|both the potential and actual engagement in physical activities\n",
      "the concept of physical activity|is concerned with|the activities that people perform as part of people everyday routines\n",
      "disability|is|a concept that centers around the limitations or restrictions of individuals\n",
      "disability|emphasizes|the things that people are unable to do or struggle with due to people condition or impairment\n",
      "three studies|were conducted|\n",
      "three studies|reported|data\n",
      "data|was related to|physical functioning\n",
      "data|was|also related to work status\n",
      "data|was|further related to disability\n",
      "data|was related|to pain severity\n",
      "two studies|were conducted|\n",
      "two studies|had|little confidence in the strength of evidence (soe)\n",
      "two studies|reported|data\n",
      "data|was related to|physical functioning\n",
      "physical functioning|was assessed|using a questionnaire or accelerometry\n",
      "dataphysical functioning|was assessed|using a questionnaire or accelerometry\n",
      "the data|was|also related to work status, disability, and pain severity\n",
      "there|were|two studies that reported data\n",
      "two studies|reported|data\n",
      "the data reported|was related to|activity in relation to work status, disability, and pain severity\n",
      "there|were|two studies that reported data\n",
      "two studies|reported|data\n",
      "data|was related to|activity, as assessed by questionnaire or accelerometry\n",
      "data|looked at|work status, disability, and pain severity\n",
      "researchers|are discussing|potential mechanisms\n",
      "potential mechanisms|include|the fear-avoidance model\n",
      "another potential mechanism|being discussed|the avoidance-endurance model\n",
      "the fear-avoidance model|suggests|that patients avoid activities\n",
      "the avoidance-endurance model|suggests|that patients avoid activities\n",
      "both models|hypothesize|that fear or avoidance plays a role in patients' activity avoidance\n",
      "patients|have|a fear of reinjury\n",
      "fear|causes|patients to avoid certain activities\n",
      "fear of reinjury|is|a feeling of being afraid that a previous injury might happen again\n",
      "deconditioning|refers to|a decrease in physical fitness or strength\n",
      "fear of reinjury|can cause|deconditioning\n",
      "deconditioning|is|a factor that contributes to disability\n",
      "deconditioning|can make|a person's disability worse\n",
      "someone|becomes|deconditioned\n",
      "disability|is worsened by|the process of deconditioning\n",
      "/mnt/clbp/paul/cross-talk/texts.examples/coref_resolved/triplets/spinal_cord.json\n",
      "the spinal column|is biomechanically stabilized|by three subsystems\n",
      "the passive subsystem|is|one of three subsystems\n",
      "passive subsystem|includes|bone, cartilage, ligaments, and intervertebral discs\n",
      "the paraspinal muscles|are|a group of muscles\n",
      "the paraspinal muscles|are responsible for|stabilizing the spinal column\n",
      "paraspinal muscles|form|active subsystem\n",
      "biomechanically|refers to|the way in which the paraspinal muscles stabilizing\n",
      "biomechanically|refers|to the way in which the muscles function in relation to the body's mechanics\n",
      "the neural control subsystem|is involved in|stabilizing the spinal column\n",
      "the neural control subsystem|plays|a role in biomechanically stabilizing the spinal column\n",
      "people|think|of the para separately\n",
      "proprioception|relies on|afferent information\n",
      "afferent information|comes|from internal peripheral areas\n",
      "proprioception and the para|have|a functional interdependence\n",
      "the para|are often conceptualized|separately\n",
      "proprioception|contributes|to postural control\n",
      "proprioception|contributes|to joint stability\n",
      "proprioception|contributes|to several conscious sensations\n",
      "afferent information|comes|from internal peripheral areas\n",
      "afferent information|functionally interdepends with|proprioception\n",
      "proprioception|contributes to|postural control, joint stability, and conscious sensations\n",
      "muscle recruitment|is|a component of motor control and function\n",
      "motor control and function|encompass|muscle recruitment\n",
      "motor control and function|involve|strength\n",
      "strength|is|a component of motor control and function\n",
      "motor control and function|include|endurance\n",
      "endurance|is|a component of motor control and function\n",
      "proprioception|is|a feedback component\n",
      "proprioception|is|important for neuromotor control\n",
      "proprioception|is|a term that describes a type of sensory information\n",
      "this sensory information|is called|afferent information\n",
      "afferent information|comes|from internal peripheral areas of the body\n",
      "proprioception|is|a factor that contributes to postural control\n",
      "proprioception|is involved|in joint stability\n",
      "proprioception|plays|a role in several conscious sensations\n",
      "movement and control disorders|are|conditions that affect a person's ability to move and control a person's body\n",
      "movement and control disorders|can result in|a deficit in proprioception\n",
      "proprioception|refers to|the body's ability to sense its position and movement in space\n",
      "there|is|a deficit in proprioception\n",
      "movement and control disorders|suggests|the body's ability to sense its position and movement in space\n",
      "deficit|means|that the person has difficulty perceiving and understanding where the person body is in relation to their body surroundings\n",
      "movement and control disorders|are|the cause of a deficit in proprioception\n",
      "stress|is placed on|local muscle spindles and joint receptors\n",
      "stress|occurs|in the painful area\n",
      "stress|is caused by|an individual's maladaptive movement\n",
      "an individual maladaptive movement|leads to|stress on a joint\n",
      "abnormal joint and tissue loading|can occur|during daily activities and postures\n",
      "abnormal joint and tissue loading|may have|an impact on local proprioceptors\n",
      "maintaining the vicious cycle|is|a possibility\n",
      "maintaining|contribute|the vicious cycle\n",
      "changes in muscle activity|have been linked to|spinal pain\n",
      "the specific model|explains|linked\n",
      "muscle tension or spasms|can cause|pain in the spine\n",
      "the pain adaptation theory|suggests|that changes in muscle activity are connected to the restriction of spinal motion\n",
      "restriction of spinal motion|can lead to|spinal pain\n",
      "the pain adaptation theory|proposes|that changes in muscle activity are a contributing factor to spinal pain\n",
      "/mnt/clbp/paul/cross-talk/texts.examples/coref_resolved/triplets/personal_medical_history.json\n",
      "a patient's personal history|is|a record of their past experiences and background information\n",
      "one aspect|is|their employment status\n",
      "employment status|refers to|whether the patient is currently employed, unemployed, or retired\n",
      "employment status|is|important for understanding the patient's financial situation and potential sources of stress or support\n",
      "a patient's personal history|is|a collection of information about them\n",
      "one aspect|is|patient's personal history\n",
      "the occupation|refers to|the job or profession that them is engaged in\n",
      "occupation|is considered as|part of them\n",
      "occupation|is considered|part of their personal history\n",
      "a patient's personal history|is|a collection of information about them\n",
      "one aspect of a patient's personal history|is|their marital status\n",
      "a patient's personal history|is|a collection of information about them\n",
      "one aspect of a patient's personal history|is|their insurance status\n",
      "patient's personal history|includes|social history\n",
      "social history|encompasses|alcohol use\n",
      "social history|encompasses|tobacco use\n",
      "social history|encompasses|substance use\n",
      "a patient's personal history|includes|personal preferences, expectations, and habits\n",
      "personal preferences, expectations, and habits|can include|things like sleep schedule, clothing choices, and diet\n",
      "the patient|has|isolated and chronic illnesses\n",
      "the medical history|is|important\n",
      "patient|has|isolated illnesses\n",
      "the patient|has|chronic illnesses\n",
      "the patient's medical history|is|important\n",
      "pain|is experienced|by each individual\n",
      "experience of pain|is influenced by|contributions of all these entities\n",
      "entities|are involved|how each individual experiences pain\n",
      "multiple entities|influence|the way pain is perceived by an individual\n",
      "the role|played|by multiple entities that are likely involved in how each individual experiences pain\n",
      "involvement of multiple entities|is likely to contribute|unique experience of pain for each individual\n",
      "the experience of pain|is influenced|by various factors\n",
      "various factors|can vary|from person to person\n",
      "each individual's experience of pain|is likely influenced|by various factors\n",
      "pain|is experienced|differently by each individual\n",
      "the experience of pain|is|likely influenced by various factors\n",
      "various factors|can include|the contributions of different entities\n",
      "entities|influence|how pain is experienced by individuals\n",
      "multiple entities|influence|how pain is experienced by individuals\n",
      "the impact of multiple entities|can vary|on the experience of pain\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from py2neo import Graph\n",
    "graph = Graph(\"bolt://localhost:7687\",password='12345678',name=\"version1\")\n",
    "\n",
    "tx = graph.begin()\n",
    "tx.run(\"MATCH (n:Paragraph) DETACH DELETE n;\")\n",
    "tx.run(\"MATCH (n:ResultSentence) DETACH DELETE n;\")\n",
    "tx.run(\"MATCH (n:Subject) DETACH DELETE n;\")\n",
    "tx.run(\"MATCH (n:Object) DETACH DELETE n;\")\n",
    "tx.run(\"MATCH (n:Entity) DETACH DELETE n;\")\n",
    "graph.commit(tx)\n",
    "\n",
    "path = '/mnt/clbp/paul/cross-talk/texts.examples/coref_resolved/triplets/'\n",
    "files = glob.glob(path+'/*.json')\n",
    "for file in files:\n",
    "    print(file)\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "    name = file.split(\"/\")[-1]\n",
    "    domain = name.split(\".\")[0]\n",
    "    tx = graph.begin()\n",
    "    for ix,item in enumerate(data):\n",
    "        paragraph = item['paragraph']\n",
    "        text = paragraph['text']\n",
    "        tx.run(\"CREATE (paragraph:Paragraph {source: $source, domain: $domain, ix: $ix, text: $text}) RETURN paragraph\", source=file.split(\"/\")[-1], domain=domain, ix=ix, text=text)\n",
    "    graph.commit(tx)\n",
    "    tx = graph.begin()\n",
    "    for ix,item in enumerate(data):\n",
    "        paragraph = item['paragraph']\n",
    "        if 'sentences_with_results' in paragraph:\n",
    "            for jx, result_sentence in enumerate(paragraph['sentences_with_results']):\n",
    "                text = result_sentence['text']\n",
    "                tx.run(\"MATCH (paragraph:Paragraph {ix: $ix, domain:$domain}) CREATE (sentence:ResultSentence {ix: $jx, text: $text})-[:FROM]->(paragraph) RETURN *\", domain=domain, ix=ix, jx=jx, text=text)\n",
    "    graph.commit(tx)\n",
    "    tx = graph.begin()\n",
    "    for ix,item in enumerate(data):\n",
    "        paragraph = item['paragraph']\n",
    "        if 'sentences_with_results' in paragraph:\n",
    "            for jx, result_sentence in enumerate(paragraph['sentences_with_results']):\n",
    "                for kx, clause in enumerate(result_sentence['clauses']):\n",
    "                    text = clause['text']\n",
    "                    triplet = clause['triplet']\n",
    "                    subject,verb,object = triplet['subject'].lower(),triplet['verb'].lower(),triplet['object'].lower()\n",
    "                    print(subject,verb,object,sep=\"|\")\n",
    "                    tx.run(\"\"\"MATCH (sentence:ResultSentence {ix:$jx})-[:FROM]->(paragraph:Paragraph {ix: $ix, domain:$domain}) \n",
    "                              CREATE (s:Subject {ix: $kx, text: $subject, from: elementId(sentence)})-[v:VERB {ix: $kx, text: $verb, from: elementId(sentence)}]->(o:Object {ix: $kx, text: $object, from: elementId(sentence)}) RETURN *\"\"\",\n",
    "                           domain=domain, ix=ix, jx=jx, kx=kx, subject=subject, verb=verb, object=object)\n",
    "    graph.commit(tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Clinical embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining/registering nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent_biobert_clinical_base_cased download started this may take some time.\n",
      "Approximate size to download 386.6 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.base import DocumentAssembler\n",
    "from sparknlp.annotator import SentenceDetector, BertSentenceEmbeddings\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.sql.functions as F\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "sentence = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "embeddings = BertSentenceEmbeddings.pretrained(\"sent_biobert_clinical_base_cased\", \"en\").setInputCols(\"sentence\").setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "pipeline = Pipeline(stages=[documentAssembler,\n",
    "                            sentence,\n",
    "                            embeddings])\n",
    "\n",
    "def get_embedding(text):\n",
    "    example_df = spark.createDataFrame([[text]]).toDF(\"text\")\n",
    "    model = pipeline.fit(example_df)\n",
    "    results = model.transform(example_df).toPandas()\n",
    "    return results['sentence_embeddings'].loc[0][0]['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.9176039052884686\n"
     ]
    }
   ],
   "source": [
    "A = get_embedding(\"data\")\n",
    "B = get_embedding(\"the data\")\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    " \n",
    "# compute cosine similarity\n",
    "cosine = (np.dot(A,B)/(norm(A)*norm(B))+1)/2\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.run(\"MATCH (s) WHERE s:Subject or s:Object SET s:SubjectOrObject return *\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "graph = Graph(password='12345678',name=\"version1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for r in graph.run(\"MATCH (z:SubjectOrObject) RETURN z\"):\n",
    "    #do something with node here\n",
    "    z = r['z']\n",
    "    text = z['text']\n",
    "    if len(text.strip()) > 2:\n",
    "        embedding = get_embedding(text.strip())\n",
    "        z['embedding'] = embedding\n",
    "        z.update()\n",
    "        tx = graph.begin()\n",
    "        tx.push(z)\n",
    "        graph.commit(tx)\n",
    "    else:\n",
    "        embedding = get_embedding(\"THIS IS AN ERROR\")\n",
    "        z['embedding'] = embedding\n",
    "        z.update()\n",
    "        tx = graph.begin()\n",
    "        tx.push(z)\n",
    "        graph.commit(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#graph.run(\"CALL db.index.vector.createNodeIndex('text-embeddings', 'SubjectOrObject', 'embedding', 768, 'cosine')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(No data)\n",
      "(No data)\n"
     ]
    }
   ],
   "source": [
    "print(graph.run(\"match (z:SubjectOrObject)-[e:COSINE_SIM]-(:SubjectOrObject) delete e\"))\n",
    "print(graph.run(\"match (z:SubjectOrObject)-[e:IS_A]-(:Entity) delete e\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sim_threshold = 0.95\n",
    "cypher = \"MATCH (z:SubjectOrObject) RETURN DISTINCT z.text\";\n",
    "for r in graph.run(cypher):\n",
    "    if len(str(r).strip()) > 2:\n",
    "        sim_cypher = \"\"\"\n",
    "    MATCH (s:SubjectOrObject {text: %s})\n",
    "    CALL db.index.vector.queryNodes('text-embeddings', 20, s.embedding)\n",
    "    YIELD node AS similar, score\n",
    "    WHERE score > %s and elementId(s) < elementId(similar)\n",
    "    MERGE (s)-[:COSINE_SIM {score: score}]-(similar)\n",
    "    return *\n",
    "        \"\"\"%(str(r),sim_threshold)\n",
    "        #print(sim_cypher)\n",
    "        try:\n",
    "            graph.run(sim_cypher)\n",
    "        except:\n",
    "            print(r)\n",
    "            import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>nodeProjection</th><th>relationshipProjection</th><th>graphName</th><th>nodeCount</th><th>relationshipCount</th><th>projectMillis</th></tr><tr><td style=\"text-align:left\">{SubjectOrObject: {label: &#039;SubjectOrObject&#039;, properties: {}}}</td><td style=\"text-align:left\">{COSINE_SIM: {aggregation: &#039;DEFAULT&#039;, orientation: &#039;NATURAL&#039;, indexInverse: false, properties: {}, type: &#039;COSINE_SIM&#039;}}</td><td style=\"text-align:left\">myGraph</td><td style=\"text-align:right\">346</td><td style=\"text-align:right\">1115</td><td style=\"text-align:right\">5</td></tr></table>"
      ],
      "text/plain": [
       " nodeProjection                                                | relationshipProjection                                                                                                  | graphName | nodeCount | relationshipCount | projectMillis \n",
       "---------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|-----------|-----------|-------------------|---------------\n",
       " {SubjectOrObject: {label: 'SubjectOrObject', properties: {}}} | {COSINE_SIM: {aggregation: 'DEFAULT', orientation: 'NATURAL', indexInverse: false, properties: {}, type: 'COSINE_SIM'}} | myGraph   |       346 |              1115 |             5 "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    graph.run(\"CALL gds.graph.drop('myGraph') YIELD graphName;\")\n",
    "except:\n",
    "    pass # graph exists\n",
    "\n",
    "graph.run(\n",
    "    \"\"\"\n",
    "CALL gds.graph.project(\n",
    "  'myGraph',\n",
    "  'SubjectOrObject',\n",
    "  'COSINE_SIM',\n",
    "  {\n",
    "  }\n",
    ")\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph.run(\"\"\"\n",
    "CALL gds.wcc.stream('myGraph')\n",
    "YIELD componentId, nodeId\n",
    "WITH gds.util.asNode(nodeId) AS n, componentId AS componentId\n",
    "SET n.componentId=componentId\n",
    "RETURN n\n",
    "\"\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph.run(\"\"\"\n",
    "MATCH (z:SubjectOrObject) with COUNT(z.componentId) as c, z.componentId as componentId\n",
    "MERGE (b:Entity {componentId: componentId})\n",
    "return *\n",
    "\"\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph.run(\"MATCH (z:Entity), (b:SubjectOrObject) WHERE b.componentId=z.componentId MERGE (z)<-[:IS_A]-(b) return *\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph.run(\"\"\"\n",
    "MATCH (s:Subject)-[v:VERB]->(o:Object)\n",
    "WITH s,v,o\n",
    "MATCH (e1:Entity {componentId:s.componentId}), (e2:Entity {componentId: o.componentId})\n",
    "with e1,v,e2\n",
    "MERGE (e1)-[:VERB2 {text: v.text, from: elementId(v)}]->(e2) RETURN *\"\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cid in graph.run(\"\"\"MATCH (z:Entity) return DISTINCT z.componentId as componentId\"\"\"):\n",
    "    cid = int(str(cid))\n",
    "    texts = []\n",
    "    for text in graph.run(\"\"\"MATCH (z:SubjectOrObject {componentId: %s}) return z.text as text\"\"\"%cid):\n",
    "        texts.append(str(text)[1:-1]) # the weird 1:-1 is because of quoting done by neo4j\n",
    "    text = max(set(texts), key=texts.count)\n",
    "    graph.run(\"\"\"MATCH (z:Entity {componentId: %s}) SET z.text = \"%s\" return *\"\"\"%(cid,text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining and registering vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[ | ]tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[ \\ ]Download done! Loading the resource.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.base import DocumentAssembler\n",
    "from sparknlp.annotator import SentenceDetector, UniversalSentenceEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.sql.functions as F\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "sentence = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "embeddings = UniversalSentenceEncoder.pretrained(\"tfhub_use\", \"en\").setInputCols(\"sentence\").setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "pipeline = Pipeline(stages=[documentAssembler,\n",
    "                            sentence,\n",
    "                            embeddings])\n",
    "\n",
    "def get_embedding2(text):\n",
    "    example_df = spark.createDataFrame([[text]]).toDF(\"text\")\n",
    "    model = pipeline.fit(example_df)\n",
    "    results = model.transform(example_df).toPandas()\n",
    "    return results['sentence_embeddings'].loc[0][0]['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.run(\"match (e:NODE_VERB2)-[r]-() delete e,r\")\n",
    "cypher = \"MATCH (a)-[r:VERB2]->(b) MERGE (e:NODE_VERB2 {text:r.text, from: elementId(a), to: elementId(b), edge: elementId(r)}) RETURN DISTINCT r.text\";\n",
    "graph.run(cypher)\n",
    "for r in graph.run(\"MATCH (z:NODE_VERB2) RETURN z\"):\n",
    "    #do something with node here\n",
    "    z = r['z']\n",
    "    text = z['text']\n",
    "    if len(text.strip()) > 2:\n",
    "        embedding = get_embedding2(text.strip())\n",
    "        z['embedding'] = embedding\n",
    "        z.update()\n",
    "        tx = graph.begin()\n",
    "        tx.push(z)\n",
    "        graph.commit(tx)\n",
    "    else:\n",
    "        embedding = get_embedding2(\"THIS IS AN ERROR\")\n",
    "        z['embedding'] = embedding\n",
    "        z.update()\n",
    "        tx = graph.begin()\n",
    "        tx.push(z)\n",
    "        graph.commit(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph.run(\"CALL db.index.vector.createNodeIndex('edge-text-embeddings', 'NODE_VERB2', 'embedding', 512, 'cosine')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(No data)\n",
      "(No data)\n"
     ]
    }
   ],
   "source": [
    "print(graph.run(\"match (z:NODE_VERB2)-[e:COSINE_SIM]-(:NODE_VERB2) delete e\"))\n",
    "print(graph.run(\"match (z:NODE_VERB2)-[e:IS_A]-(:Entity_VERB2) delete e\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sim_threshold = 0.9\n",
    "cypher = \"MATCH (z:NODE_VERB2) RETURN DISTINCT z.text\";\n",
    "for r in graph.run(cypher):\n",
    "    if len(str(r).strip()) > 2:\n",
    "        sim_cypher = \"\"\"\n",
    "    MATCH (s:NODE_VERB2 {text: %s})\n",
    "    CALL db.index.vector.queryNodes('edge-text-embeddings', 20, s.embedding)\n",
    "    YIELD node AS similar, score\n",
    "    WHERE score > %s and elementId(s) < elementId(similar)\n",
    "    return elementId(s) as s,elementId(similar) as similar,score\n",
    "        \"\"\"%(str(r),sim_threshold)\n",
    "        for r in graph.run(sim_cypher):\n",
    "            s = r['s']\n",
    "            similar = r['similar']\n",
    "            score = r['score']\n",
    "            graph.run(\"MATCH (s:NODE_VERB2),(similar:NODE_VERB2) where elementId(s)='%s' and elementId(similar)='%s'  MERGE (s)-[e:COSINE_SIM {score: %s}]-(similar) return e.score\"%(s,similar,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>nodeProjection</th><th>relationshipProjection</th><th>graphName</th><th>nodeCount</th><th>relationshipCount</th><th>projectMillis</th></tr><tr><td style=\"text-align:left\">{NODE_VERB2: {label: &#039;NODE_VERB2&#039;, properties: {}}}</td><td style=\"text-align:left\">{COSINE_SIM: {aggregation: &#039;DEFAULT&#039;, orientation: &#039;NATURAL&#039;, indexInverse: false, properties: {}, type: &#039;COSINE_SIM&#039;}}</td><td style=\"text-align:left\">myGraph2</td><td style=\"text-align:right\">173</td><td style=\"text-align:right\">388</td><td style=\"text-align:right\">14</td></tr></table>"
      ],
      "text/plain": [
       " nodeProjection                                      | relationshipProjection                                                                                                  | graphName | nodeCount | relationshipCount | projectMillis \n",
       "-----------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|-----------|-----------|-------------------|---------------\n",
       " {NODE_VERB2: {label: 'NODE_VERB2', properties: {}}} | {COSINE_SIM: {aggregation: 'DEFAULT', orientation: 'NATURAL', indexInverse: false, properties: {}, type: 'COSINE_SIM'}} | myGraph2  |       173 |               388 |            14 "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    graph.run(\"CALL gds.graph.drop('myGraph2') YIELD graphName;\")\n",
    "except:\n",
    "    pass # graph exists\n",
    "\n",
    "graph.run(\n",
    "    \"\"\"\n",
    "CALL gds.graph.project(\n",
    "  'myGraph2',\n",
    "  'NODE_VERB2',\n",
    "  'COSINE_SIM',\n",
    "  {\n",
    "  }\n",
    ")\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.run(\"\"\"\n",
    "CALL gds.wcc.stream('myGraph2')\n",
    "YIELD componentId, nodeId\n",
    "WITH gds.util.asNode(nodeId) AS n, componentId AS componentId\n",
    "SET n.componentId=componentId\n",
    "RETURN n\n",
    "\"\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.run(\"\"\"\n",
    "MATCH (z:NODE_VERB2) with COUNT(z.componentId) as c, z.componentId as componentId\n",
    "MERGE (b:Entity_VERB2 {componentId: componentId})\n",
    "return *\n",
    "\"\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.run(\"MATCH (z:Entity_VERB2), (b:NODE_VERB2) WHERE b.componentId=z.componentId MERGE (z)<-[:IS_A]-(b) return *\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cid in graph.run(\"\"\"MATCH (z:Entity_VERB2) return DISTINCT z.componentId as componentId\"\"\"):\n",
    "    cid = int(str(cid))\n",
    "    texts = []\n",
    "    for text in graph.run(\"\"\"MATCH (z:NODE_VERB2 {componentId: %s}) return z.text as text\"\"\"%cid):\n",
    "        texts.append(str(text)[1:-1]) # the weird 1:-1 is because of quoting done by neo4j\n",
    "    if len(texts) > 0:\n",
    "        text = max(set(texts), key=texts.count)\n",
    "        graph.run(\"\"\"MATCH (z:Entity_VERB2 {componentId: %s}) SET z.text = \"%s\" return *\"\"\"%(cid,text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.run(\"\"\"\n",
    "MATCH (e1:Entity)-[v:VERB2]-(e2:Entity)\n",
    "MATCH (nv:NODE_VERB2 {text: v.text})-[:IS_A]->(ev:Entity_VERB2)\n",
    "WITH e1,e2,ev\n",
    "MERGE (e1)-[:VERB3 {text: ev.text}]-(e2)\n",
    "RETURN *\"\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "name": "10.Clinical_Relation_Extraction",
  "notebookId": 781554605447210,
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
